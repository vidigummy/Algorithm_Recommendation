{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm6qpMgBo4iL",
        "outputId": "e12a918b-8bb4-4bb7-d4ba-216a4246247a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import heapq\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import multiprocessing\n",
        "from worker import worker\n",
        "from IPython.display import clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 데이터 가공\n",
        "userId_problemId.csv 파일 필요"
      ],
      "metadata": {
        "id": "cLUDbHD6tUIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./data/userId_problemId.csv\").loc[:,['userId', 'problemId']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9S15_wWOqlrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9e285579-6534-4b81-e2ac-a086686c6633"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  problemId\n",
              "0  sos0911       1000\n",
              "1  sos0911       1001\n",
              "2  sos0911       1002\n",
              "3  sos0911       1003\n",
              "4  sos0911       1005"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6628919e-9165-4644-a26c-0d271092d65c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>problemId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sos0911</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sos0911</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sos0911</td>\n",
              "      <td>1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sos0911</td>\n",
              "      <td>1003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sos0911</td>\n",
              "      <td>1005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6628919e-9165-4644-a26c-0d271092d65c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6628919e-9165-4644-a26c-0d271092d65c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6628919e-9165-4644-a26c-0d271092d65c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) userId remapping"
      ],
      "metadata": {
        "id": "YDzVw2frtXET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remap_user():\n",
        "    user_problem_df = pd.read_csv(\"./data/userId_problemId.csv\").loc[:, ['userId', 'problemId']]\n",
        "    user_df = pd.DataFrame({\"user_id\": [], \"remap_id\": []}).astype({'remap_id':'int'})\n",
        "    unique_user = user_problem_df['userId'].unique().tolist()\n",
        "    for i in range(len(unique_user)):\n",
        "        new_user_df = pd.DataFrame({\"user_id\": [unique_user[i]], \"remap_id\": [i]})\n",
        "        user_df = pd.concat((user_df, new_user_df))\n",
        "        \n",
        "    user_df.to_csv(\"./data/user_list.csv\", index=False)"
      ],
      "metadata": {
        "id": "RtTOGWMUtQx4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) problemId remapping"
      ],
      "metadata": {
        "id": "PNoHgbOBtY6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remap_problem():\n",
        "    user_problem_df = pd.read_csv(\"./data/userId_problemId.csv\").loc[:, ['userId', 'problemId']]\n",
        "    problem_df = pd.DataFrame({\"problem_id\": [], \"remap_id\": []}).astype({'remap_id':'int'})\n",
        "    unique_sorted_problem = sorted(user_problem_df['problemId'].unique().tolist())\n",
        "    for i in range(len(unique_sorted_problem)):\n",
        "        new_problem_df = pd.DataFrame({\"problem_id\": [unique_sorted_problem[i]], \"remap_id\": [i]})\n",
        "        problem_df = pd.concat((problem_df, new_problem_df))\n",
        "    \n",
        "    problem_df.to_csv(\"./data/problem_list.csv\", index=False)"
      ],
      "metadata": {
        "id": "kO3kEm6-tYTf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Convert userId, problemId"
      ],
      "metadata": {
        "id": "bvw2dsc6tcqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remap_user_problem():\n",
        "    user_problem_df = pd.read_csv(\"./data/userId_problemId.csv\").loc[:, ['userId', 'problemId']]\n",
        "    user_df = pd.read_csv(\"./data/user_list.csv\")\n",
        "    problem_df = pd.read_csv(\"./data/problem_list.csv\")\n",
        "\n",
        "    manager = multiprocessing.Manager()\n",
        "    user_problem_remap_df = pd.DataFrame({'userId': [], 'problemId': []}).astype('int')\n",
        "\n",
        "    for i in range(0, user_problem_df['userId'].size, 10000):\n",
        "        clear_output(wait=True)\n",
        "        print('Loading: [{}]'.format('-' * (i // 10000) + '>' + '-' * (83 - i // 10000)))\n",
        "        \n",
        "        return_dict = manager.dict()\n",
        "        jobs = []\n",
        "        \n",
        "        for j in range(4):\n",
        "            p = multiprocessing.Process(target=worker, args=(j, i + 2500 * j, user_df, problem_df, user_problem_df[i + 2500 * j:i + min(user_problem_df['userId'].size, 2500*(j+1))], return_dict))\n",
        "            jobs.append(p)\n",
        "            p.start()\n",
        "            if i + 2500 * (j+1) >= user_problem_df['userId'].size: break\n",
        "        for proc in jobs:\n",
        "            proc.join()\n",
        "            proc.close()\n",
        "        for j in range(len(return_dict.keys())):\n",
        "            user_problem_remap_df = pd.concat((user_problem_remap_df, return_dict[j]))\n",
        "    user_problem_remap_df.to_csv(\"./data/userId_problemId_remap.csv\", index=False)"
      ],
      "metadata": {
        "id": "oK5oz3matcO4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile('./data/user_list.csv'):\n",
        "    print('user_list.csv file already exist')\n",
        "else: \n",
        "    remap_user()\n",
        "    print('user_list file saved successfully')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vytaxrOotiJe",
        "outputId": "44015654-ad88-4bc8-96df-11ecf5a4cdeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_list.csv file already exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile('./data/problem_list.csv'):\n",
        "    print('problem_list.csv file already exist')\n",
        "else:\n",
        "    remap_problem()\n",
        "    print('problem_list file saved successfully')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieHaZKROtlTm",
        "outputId": "6c196f54-46e6-451f-cf59-e6945a5fb761"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "problem_list.csv file already exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiprocessing을 사용하여 30분 이상 걸리던 작업을 13분으로 단축"
      ],
      "metadata": {
        "id": "GKCMiJsAtq6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile('./data/userId_problemId_remap.csv'):\n",
        "    print('userId_problemId_remap.csv file already exist')\n",
        "else:\n",
        "    remap_user_problem()\n",
        "    print('userId_problemId_remap file saved successfully')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPGmdhM0tm-k",
        "outputId": "bf671e9d-748e-4936-f843-3876db7275f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userId_problemId_remap.csv file already exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train data, test data 생성"
      ],
      "metadata": {
        "id": "lxQdJFTkttde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def making_data():\n",
        "\n",
        "    if os.path.isfile('./data/train.txt') and os.path.isfile('./data/test.txt'):\n",
        "        print('train.txt test.txt file already exist')\n",
        "        return\n",
        "\n",
        "    user_problem_remap_df = pd.read_csv(\"./data/userId_problemId_remap.csv\").loc[:, ['userId', 'problemId']]\n",
        "    train_data_df = pd.DataFrame({'userId': [], 'problemId': []}, dtype=int)\n",
        "    test_data_df = pd.DataFrame({'userId': [], 'problemId': []}, dtype=int)\n",
        "    \n",
        "    for user_id in user_problem_remap_df['userId'].unique():\n",
        "        problem_list = user_problem_remap_df[user_problem_remap_df['userId'] == user_id]['problemId'].tolist()\n",
        "        train_problem_list = random.sample(problem_list, int(len(problem_list) * 0.8))\n",
        "        test_problem_list = list(set(problem_list) - set(train_problem_list))\n",
        "        \n",
        "        new_train_data_df = pd.DataFrame({'userId': [user_id], 'problemId': [train_problem_list]})\n",
        "        new_test_data_df = pd.DataFrame({'userId': [user_id], 'problemId': [test_problem_list]})\n",
        "        \n",
        "        train_data_df = pd.concat((train_data_df, new_train_data_df))\n",
        "        test_data_df = pd.concat((test_data_df, new_test_data_df))\n",
        "    \n",
        "    with open(\"./data/train.txt\", \"w\") as f:\n",
        "        for user_id in sorted(train_data_df['userId'].tolist()):\n",
        "            problem_list = [*map(int, train_data_df[train_data_df['userId'] == user_id]['problemId'].tolist()[0])]\n",
        "            f.write(str(user_id) + ' ' + ' '.join(map(str, problem_list)) + '\\n')\n",
        "    \n",
        "    with open(\"./data/test.txt\", \"w\") as f:\n",
        "        for user_id in sorted(test_data_df['userId'].tolist()):\n",
        "            problem_list = [*map(int, test_data_df[test_data_df['userId'] == user_id]['problemId'].tolist()[0])]\n",
        "            f.write(str(user_id) + ' ' + ' '.join(map(str, problem_list)) + '\\n')\n",
        "        \n",
        "    print('train.txt, test.txt saved successfully')"
      ],
      "metadata": {
        "id": "5QHgf8I2tpCK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "making_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dx9jR-0tvO7",
        "outputId": "9ed38500-9a1a-4c90-858c-a01c8b974cbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.txt test.txt file already exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NGCF 모델 관련 코드"
      ],
      "metadata": {
        "id": "lI7AIfcCtxbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전역변수 설정"
      ],
      "metadata": {
        "id": "Z2Xq4bIRtyFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_items, test_set = {}, {}\n",
        "matrix = None\n",
        "exist_users = []\n",
        "global_epoch_value = 0\n",
        "result_arr = []\n",
        "\n",
        "n_users, n_items, n_train, n_test = 0, 0, 0, 0\n",
        "total_epoch = 2000\n",
        "embed_size = 64\n",
        "batch_size = 1024\n",
        "layer_size = [64, 64, 64]"
      ],
      "metadata": {
        "id": "ENuY5LnMtwJr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NGCF 모델"
      ],
      "metadata": {
        "id": "Z03bCWbit0wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NGCF(nn.Module):\n",
        "    def __init__(self, n_user, n_item, norm_adj, emb_size, batch_size, layer_size):\n",
        "        super(NGCF, self).__init__()\n",
        "        self.n_user = n_user\n",
        "        self.n_item = n_item\n",
        "        self.norm_adj = norm_adj.cuda()\n",
        "        self.emb_size = emb_size\n",
        "        self.batch_size = batch_size\n",
        "        self.layer_size = layer_size\n",
        "\n",
        "        self.embedding_dict, self.weight_dict = self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        embedding_dict = nn.ParameterDict({\n",
        "            'user_emb': nn.Parameter(nn.init.xavier_uniform_(torch.empty(self.n_user, self.emb_size))),\n",
        "            'item_emb': nn.Parameter(nn.init.xavier_uniform_(torch.empty(self.n_item, self.emb_size)))\n",
        "        })\n",
        "\n",
        "        weight_dict = nn.ParameterDict()\n",
        "        layers = [self.emb_size] + self.layer_size\n",
        "        for i in range(len(self.layer_size)):\n",
        "            weight_dict['W_gc_%d' % i] = nn.Parameter(nn.init.xavier_uniform_(torch.empty(layers[i], layers[i + 1])))\n",
        "            weight_dict['W_bi_%d' % i] = nn.Parameter(nn.init.xavier_uniform_(torch.empty(layers[i], layers[i + 1])))\n",
        "\n",
        "        return embedding_dict, weight_dict\n",
        "\n",
        "    def rating(self, u_g_embeddings, pos_i_g_embeddings):\n",
        "        return torch.matmul(u_g_embeddings, pos_i_g_embeddings.t())\n",
        "\n",
        "    def forward(self, users, pos_items, neg_items):\n",
        "        ego_embeddings = torch.cat([self.embedding_dict['user_emb'], self.embedding_dict['item_emb']], 0)\n",
        "        all_embeddings = [ego_embeddings]\n",
        "\n",
        "        for i in range(len(self.layer_size)):\n",
        "            side_embeddings = torch.mm(self.norm_adj, ego_embeddings)\n",
        "\n",
        "            sum_embeddings = torch.matmul(ego_embeddings, self.weight_dict['W_gc_%d' % i])\n",
        "            bi_embeddings = torch.mul(ego_embeddings, side_embeddings)\n",
        "            bi_embeddings = torch.matmul(bi_embeddings, self.weight_dict['W_gc_%d' % i])\n",
        "\n",
        "            ego_embeddings = nn.LeakyReLU(negative_slope=0.2)(sum_embeddings + bi_embeddings)\n",
        "            norm_embeddings = F.normalize(ego_embeddings, p=2, dim=1)\n",
        "            all_embeddings += [norm_embeddings]\n",
        "\n",
        "        all_embeddings = torch.cat(all_embeddings, 1)\n",
        "        u_g_embeddings = all_embeddings[:self.n_user, :]\n",
        "        i_g_embeddings = all_embeddings[self.n_user:, :]\n",
        "\n",
        "        u_g_embeddings = u_g_embeddings[users, :]\n",
        "        pos_i_g_embeddings = i_g_embeddings[pos_items, :]\n",
        "        neg_i_g_embeddings = i_g_embeddings[neg_items, :]\n",
        "\n",
        "        return u_g_embeddings, pos_i_g_embeddings, neg_i_g_embeddings\n",
        "\n",
        "    def BPR_Loss(self, users, pos_items, neg_items):\n",
        "        pos_scores = torch.sum(torch.mul(users, pos_items), axis=1)\n",
        "        neg_scores = torch.sum(torch.mul(users, neg_items), axis=1)\n",
        "\n",
        "        maxi = nn.LogSigmoid()(pos_scores - neg_scores)\n",
        "\n",
        "        mf_loss = -1 * torch.mean(maxi)\n",
        "\n",
        "        regularizer = (torch.norm(users) ** 2 + torch.norm(pos_items) ** 2 + torch.norm(neg_items) ** 2) / 2\n",
        "        decay = 1e-5\n",
        "        emb_loss = decay * regularizer / self.batch_size\n",
        "\n",
        "        return mf_loss + emb_loss"
      ],
      "metadata": {
        "id": "F_TVKh_xtz0t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리"
      ],
      "metadata": {
        "id": "U_v8jmU4t2Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_load():\n",
        "    global n_users, n_items, n_train, n_test, matrix\n",
        "\n",
        "    train_file = './data/train.txt'\n",
        "    test_file = './data/test.txt'\n",
        "\n",
        "    with open(train_file) as f:\n",
        "        for line in f.readlines():\n",
        "            x = line.strip().split()\n",
        "\n",
        "            user_id = int(x[0])\n",
        "            exist_users.append(user_id)\n",
        "            n_users = max(n_users, user_id)\n",
        "\n",
        "            items = [*map(int, x[1:])]\n",
        "            n_items = max(n_items, max(items))\n",
        "\n",
        "            n_train += len(items)\n",
        "\n",
        "    with open(test_file) as f:\n",
        "        for line in f.readlines():\n",
        "            x = line.strip().split()\n",
        "\n",
        "            items = [*map(int, x[1:])]\n",
        "            n_items = max(n_items, max(items))\n",
        "            n_test += len(items)\n",
        "\n",
        "    n_users += 1\n",
        "    n_items += 1\n",
        "\n",
        "    matrix = torch.zeros((n_users, n_items))\n",
        "\n",
        "    with open(train_file) as f_train:\n",
        "        with open(test_file) as f_test:\n",
        "            for line in f_train.readlines():\n",
        "                x = line.strip().split()\n",
        "                items = [*map(int, x)]\n",
        "                user_id, t_items = items[0], items[1:]\n",
        "                for item in t_items:\n",
        "                    matrix[user_id, item] = 1\n",
        "                train_items[user_id] = t_items\n",
        "            for line in f_test.readlines():\n",
        "                x = line.strip().split()\n",
        "                items = [*map(int, x)]\n",
        "                user_id, t_items = items[0], items[1:]\n",
        "                test_set[user_id] = t_items"
      ],
      "metadata": {
        "id": "7CAdhgdxt1-d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습할 때 필요한 함수"
      ],
      "metadata": {
        "id": "TOZh7BwWuBap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample():\n",
        "    if batch_size <= n_users:\n",
        "        users = random.sample(exist_users, batch_size)\n",
        "    else:\n",
        "        users = [random.choice(exist_users) for i in range(batch_size)]\n",
        "\n",
        "    pos_items, neg_items = [], []\n",
        "    for user in users:\n",
        "        pos_item_list = train_items[user]\n",
        "        pos_batch = pos_item_list[np.random.randint(0, len(pos_item_list))]\n",
        "        pos_items += [pos_batch]\n",
        "\n",
        "        while 1:\n",
        "            neg_item_list = train_items[user]\n",
        "            neg_id = np.random.randint(0, n_items)\n",
        "            if neg_id not in train_items[user] and neg_id not in neg_item_list:\n",
        "                neg_items.append(neg_id)\n",
        "                break\n",
        "    return users, pos_items, neg_items\n",
        "\n",
        "\n",
        "def get_norm_adj():\n",
        "    adj_mat = torch.zeros([n_users + n_items, n_users + n_items])\n",
        "    adj_mat[:n_users, n_users:] = matrix\n",
        "    adj_mat[n_users:, :n_users] = matrix.T\n",
        "    rowsum = np.array(adj_mat.sum(1))\n",
        "    d_inv = rowsum.copy()\n",
        "    for i in range(rowsum.size):\n",
        "        if d_inv[i] != 0:\n",
        "            d_inv[i] = 1 / d_inv[i]\n",
        "    d_mat_inv = np.diag(d_inv)\n",
        "\n",
        "    return torch.from_numpy(d_mat_inv.dot(adj_mat))"
      ],
      "metadata": {
        "id": "sGqT_VzyuAKS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 평가할 때 필요한 함수"
      ],
      "metadata": {
        "id": "WxZOHFZuuEcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n",
        "\n",
        "    item_score = {}\n",
        "    for i in test_items:\n",
        "        item_score[i] = rating[i]\n",
        "    K_max = Ks\n",
        "    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n",
        "\n",
        "    if (global_epoch_value + 1) % 100 == 0:\n",
        "        path = f'./drive/MyDrive/data/rank_{global_epoch_value+1}.txt'\n",
        "        f = open(path, 'a')\n",
        "        f.write(' '.join(map(str, K_max_item_score)) + '\\n')\n",
        "        f.close()\n",
        "    r = []\n",
        "    for val in K_max_item_score:\n",
        "        if val in user_pos_test:\n",
        "            r += [1]\n",
        "        else:\n",
        "            r += [0]\n",
        "    return r\n",
        "\n",
        "\n",
        "def get_performance(r, Ks):\n",
        "    return np.mean(np.asarray(r)[:Ks])\n",
        "\n",
        "\n",
        "def test_one_user(x, y):\n",
        "    rating = x\n",
        "    user = y\n",
        "    if len(train_items[user]) == 0:\n",
        "        training_items = []\n",
        "    else:\n",
        "        training_items = train_items[user]\n",
        "\n",
        "    user_pos_test = test_set[user]\n",
        "    all_items = set(range(n_items))\n",
        "    test_items = list(all_items - set(training_items))\n",
        "    r = ranklist_by_heapq(user_pos_test, test_items, rating, 2000)\n",
        "\n",
        "    return get_performance(r, 2000)\n",
        "\n",
        "\n",
        "def test(model, users_to_test):\n",
        "    result = 0\n",
        "    u_batch_size = batch_size * 2\n",
        "\n",
        "    test_users = users_to_test\n",
        "    n_test_users = len(test_users)\n",
        "    n_users_batchs = n_test_users // u_batch_size + 1\n",
        "\n",
        "    for u_batch_id in range(n_users_batchs):\n",
        "        start = u_batch_id * u_batch_size\n",
        "        end = (u_batch_id + 1) * u_batch_size\n",
        "\n",
        "        user_batch = test_users[start:end]\n",
        "        item_batch = range(n_items)\n",
        "        u_g_embedding, pos_i_g_embedding, _ = model(user_batch, item_batch, [])\n",
        "        rate_batch = model.rating(u_g_embedding, pos_i_g_embedding).detach().cpu()\n",
        "\n",
        "        for i in range(len(user_batch)):\n",
        "            result += test_one_user(rate_batch.numpy()[i], user_batch[i])\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "wH7jCTGouDLH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 실행"
      ],
      "metadata": {
        "id": "Hgs5CZ3EuG3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_result(epoch_value = 2000, flag = True):\n",
        "    '''\n",
        "    :param epoch_value: epoch 값\n",
        "    :param flag: True면 이미 저장된 값을 return, False면 새로 학습시켜서 return\n",
        "    :return: 각 유저에게 유사도가 제일 높은 순서로 문제 번호를 반환하는 2차원 리스트\n",
        "    '''\n",
        "    global n_users, n_items, n_train, n_test, total_epoch, embed_size, batch_size, global_epoch_value\n",
        "\n",
        "    result_arr = []\n",
        "\n",
        "    if flag:\n",
        "        if os.path.isfile(f'./drive/MyDrive/data/rank.txt'):\n",
        "            print('file exist')\n",
        "            f = open(f'./drive/MyDrive/data/rank.txt', 'r')\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                result_arr.append([*line.strip().split()])\n",
        "            f.close()\n",
        "            return result_arr\n",
        "        else:\n",
        "            print('file does not exist')\n",
        "\n",
        "    n_users, n_items, n_train, n_test = 0, 0, 0, 0\n",
        "    data_load()\n",
        "    norm_adj = get_norm_adj()\n",
        "    total_epoch = epoch_value\n",
        "    embed_size = 64\n",
        "    batch_size = 1024\n",
        "    layer_size = [64, 64, 64]\n",
        "\n",
        "    max_model_value = 0\n",
        "    for i in range(100, 2001, 100):\n",
        "        if os.path.isfile(f'./drive/MyDrive/model/NGCF_model_{i}.pkl'):\n",
        "            max_model_value = i\n",
        "    if max_model_value != 0:\n",
        "        print(f'file exist NGCF_model_{max_model_value}')\n",
        "        model = joblib.load(f'./drive/MyDrive/model/NGCF_model_{max_model_value}.pkl')\n",
        "    else: model = NGCF(n_users, n_items, norm_adj, embed_size, batch_size, layer_size).cuda()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    for epoch in range(total_epoch):\n",
        "        global_epoch_value = epoch\n",
        "        time1 = time.time()\n",
        "\n",
        "        loss = 0\n",
        "        n_batch = n_train // batch_size + 1\n",
        "        for idx in range(n_batch):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            users, pos_items, neg_items = sample()\n",
        "            u_g_embedding, pos_i_g_embedding, neg_i_g_embedding = model(users, pos_items, neg_items)\n",
        "            batch_loss = model.BPR_Loss(u_g_embedding, pos_i_g_embedding, neg_i_g_embedding)\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss += batch_loss\n",
        "\n",
        "        time2 = time.time()\n",
        "        print(f'Epoch: {epoch}, loss: {loss}, time: {int(time2 - time1)}')\n",
        "\n",
        "        users_to_test = list(test_set.keys())\n",
        "        ret = test(model, users_to_test)\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print(f'Precision: {ret}')\n",
        "        if (epoch+1) % 100 == 0:\n",
        "            joblib.dump(model, f'./drive/MyDrive/model/NGCF_model_{epoch+1}.pkl')\n",
        "\n",
        "    \n",
        "    f = open(f'./drive/MyDrive/data/rank.txt', 'r')\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        result_arr.append([*line.strip().split()])\n",
        "    f.close()\n",
        "    return result_arr"
      ],
      "metadata": {
        "id": "zfUo9DFouFre"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습된 결과 얻기"
      ],
      "metadata": {
        "id": "7vhR4mD1uJx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "get_result(epoch_value = 2000, flag = True)\n",
        "epoch_value = epoch 설정\n",
        "flag = 이미 저장된 파일 불러오려면 True, 새로 학습하려면 False\n",
        "'''\n",
        "\n",
        "user_problem_list = get_result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5d2gZ8QuIgD",
        "outputId": "d8fac9fc-2b56-4909-fb79-3a75d1721e99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 출력\n",
        "\n",
        "1. 유저가 이미 풀은 문제는 제외\n",
        "2. 유저 id와 문제 id가 매핑되어 있으므로 원래대로 바꾸어줌"
      ],
      "metadata": {
        "id": "BTHiXcbJ10dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def except_solved_problem(recommender_list):\n",
        "    problem_title_level_df = pd.read_csv(\"./data/userId_problemId.csv\").loc[:, ['problemId', 'title', 'level']]\n",
        "    user_problem_remap_df = pd.read_csv(\"./data/userId_problemId_remap.csv\").loc[:, ['userId', 'problemId']]\n",
        "    user_df = pd.read_csv(\"./data/user_list.csv\")\n",
        "    problem_df = pd.read_csv(\"./data/problem_list.csv\")\n",
        "    \n",
        "    print(user_df.head())\n",
        "\n",
        "    s = input(\"Search user name: \")\n",
        "\n",
        "    try:\n",
        "        user_id = int(user_df[user_df['user_id'] == s]['remap_id'])\n",
        "    except:\n",
        "        print('cannot found user')\n",
        "        return []\n",
        "\n",
        "\n",
        "    user_recommender_list = recommender_list[user_id]\n",
        "    search_user_df = user_problem_remap_df[user_problem_remap_df['userId'] == user_id]\n",
        "    \n",
        "    # remap_id → boj 문제 번호\n",
        "    boj_problem_list = []\n",
        "    for rec_id in user_recommender_list:\n",
        "        if search_user_df[search_user_df['problemId'] == float(rec_id)].size != 0:\n",
        "            boj_problem_list.append(int(problem_df[problem_df['remap_id'] == int(rec_id)]['problem_id']))\n",
        "    \n",
        "    # boj 문제 번호 -> search level, title\n",
        "\n",
        "    res_boj_info = []\n",
        "    for boj_problem_id in boj_problem_list:\n",
        "        df = problem_title_level_df[problem_title_level_df['problemId'] == boj_problem_id].iloc[0]\n",
        "        if 5 < df['level'] <= 15:\n",
        "            res_boj_info.append([df['problemId'], df['title'], df['level']])\n",
        "\n",
        "\n",
        "    return res_boj_info\n"
      ],
      "metadata": {
        "id": "pbOCKqMDuTYc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_arr = except_solved_problem(user_problem_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDewrOLQNAIi",
        "outputId": "dbaba295-84e8-4329-aa1f-16129514e308"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    user_id  remap_id\n",
            "0   sos0911         0\n",
            "1   dnfl182         1\n",
            "2   hja5432         2\n",
            "3  jhnan917         3\n",
            "4  siontama         4\n",
            "Search user name: alstjr3060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tier = ['Bronze', 'Silver', 'Gold']\n",
        "tier_list = ['Unrank']\n",
        "for i in range(3):\n",
        "    for j in range(5):\n",
        "        tier_list.append(f'{tier[i]} {j+1}')\n",
        "\n",
        "problem_tag_df = pd.read_csv(\"./data/problem_category.csv\").loc[:, ['problemId', 'category']]\n",
        "for i in range(10):\n",
        "    val, title, level = res_arr[i]\n",
        "    tag = problem_tag_df[problem_tag_df['problemId'] == val]['category'].tolist()\n",
        "    print(f'BOJ {val}\\n문제 이름: {title}\\n문제 난이도: {tier_list[level]}\\n문제 유형: {\", \".join(tag)}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32IV_S7RaCec",
        "outputId": "8fd04feb-23e9-446d-b6ad-7a61dcf0af16"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOJ 15651\n",
            "문제 이름: N과 M (3)\n",
            "문제 난이도: Silver 3\n",
            "문제 유형: backtracking\n",
            "\n",
            "BOJ 7562\n",
            "문제 이름: 나이트의 이동\n",
            "문제 난이도: Silver 5\n",
            "문제 유형: bfs, graph_traversal, graphs\n",
            "\n",
            "BOJ 1436\n",
            "문제 이름: 영화감독 숌\n",
            "문제 난이도: Silver 1\n",
            "문제 유형: bruteforcing\n",
            "\n",
            "BOJ 14888\n",
            "문제 이름: 연산자 끼워넣기\n",
            "문제 난이도: Silver 5\n",
            "문제 유형: backtracking, bruteforcing\n",
            "\n",
            "BOJ 15657\n",
            "문제 이름: N과 M (8)\n",
            "문제 난이도: Silver 3\n",
            "문제 유형: backtracking\n",
            "\n",
            "BOJ 10816\n",
            "문제 이름: 숫자 카드 2\n",
            "문제 난이도: Silver 2\n",
            "문제 유형: binary_search, data_structures, sorting\n",
            "\n",
            "BOJ 10814\n",
            "문제 이름: 나이순 정렬\n",
            "문제 난이도: Silver 1\n",
            "문제 유형: sorting\n",
            "\n",
            "BOJ 11054\n",
            "문제 이름: 가장 긴 바이토닉 부분 수열\n",
            "문제 난이도: Gold 3\n",
            "문제 유형: dp\n",
            "\n",
            "BOJ 1012\n",
            "문제 이름: 유기농 배추\n",
            "문제 난이도: Silver 4\n",
            "문제 유형: bfs, dfs, graph_traversal, graphs\n",
            "\n",
            "BOJ 15666\n",
            "문제 이름: N과 M (12)\n",
            "문제 난이도: Silver 4\n",
            "문제 유형: backtracking\n",
            "\n"
          ]
        }
      ]
    }
  ]
}